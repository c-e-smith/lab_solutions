{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  ![](https://ga-dash.s3.amazonaws.com/production/assets/logo-9f88ae6c9c3871690e33280fcf557f33.png) Lab 3.04 | Regression Metrics Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 1: Build a function called `r2_adj()` that will calculate $R^2_{adj}$ for a model. For inputs, you'll need `y_true`, `y_preds`, the number of variables $p$, and the number of observations $n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "import numpy as np\n",
    "\n",
    "def r2_adj(y_true, y_preds, p, n):\n",
    "    y_mean = np.mean(y_true)\n",
    "    numerator = np.sum(np.square(y_true - y_preds)) / (n - p - 1)\n",
    "    denominator = np.sum(np.square(y_true - y_mean)) / (n - 1)\n",
    "    return numerator / denominator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 2: Using the forest fire data from the lesson, build two models in `statsmodels`, one of which should include at least one newly-engineered feature. \n",
    "\n",
    "Test your output of Exercise 1 by running `r2_adj()` on both models and by checking `.summary()` of the models. (Adjusted $R^2$ is in the summary.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 3: Suppose we build two models. Model 1 has predicted outputs `y_preds_1` and Model 2 has predicted outputs `y_preds_2`. We now have the question we'll always have:\n",
    "\n",
    "![](https://spoonuniversity.com/wp-content/uploads/sites/87/2016/06/Rebecca-Black-Friday-Which-Seat-Can-I-Take-Meme-26.gif)\n",
    "\n",
    "*(Okay, maybe which model should I pick?)*\n",
    "\n",
    "Build a function:\n",
    "- called `model_picker()`\n",
    "- that accepts `y_true`, `y_preds_1`, and `y_preds_2` as inputs, and\n",
    "- returns:\n",
    "    - $R^2$, MSE, RMSE, MedAE, and MSLE for model 1,\n",
    "    - $R^2$, MSE, RMSE, MedAE, and MSLE for model 2,\n",
    "    - \"Model 1 is the model to pick!\" if all of Model 1's scores are better than Model 2,\n",
    "    - \"Model 2 is the model to pick!\" if all of Model 2's scores are better than Model 1, or\n",
    "    - \"Neither model wins.\" if neither model is uniformly better than the other.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "\n",
    "def model_picker(y_true, y_preds_1, y_preds2):\n",
    "    return (\n",
    "    \"Model 1 R2:\" + metrics.r2_score(y_preds_1,y_true),\n",
    "    \"Model 1 MSE: \" + metrics.mean_squared_error(y_preds_1,y_true),\n",
    "    \"Model 1 RMSE: \" + metrics.mean_squared_error(y_preds_1,y_true) ** 0.5,\n",
    "    \"Model 1 MedAE: \" + metrics.median_absolute_error(y_preds_1,y_true),\n",
    "    \"Model 1 MSLE: \" + metrics.mean_squared_log_error(y_preds_1, y_true),\n",
    "    \"Model 2 R2:\" + metrics.r2_score(y_preds_2,y_true),\n",
    "    \"Model 2 MSE: \" + metrics.mean_squared_error(y_preds_2,y_true),\n",
    "    \"Model 2 RMSE: \" + metrics.mean_squared_error(y_preds_2,y_true) ** 0.5,\n",
    "    \"Model 2 MedAE: \" + metrics.median_absolute_error(y_preds_2,y_true),\n",
    "    \"Model 2 MSLE: \" + metrics.mean_squared_log_error(y_preds_2, y_true)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 4: Using the forest fire data from the lesson, build two models in `scikit-learn`, one of which should include at least one newly-engineered feature. \n",
    "\n",
    "Test your output of Exercise 1 by running `r2_adj()` on both models and by checking `.summary()` of the models. (Adjusted $R^2$ is in the summary.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BONUS: Adapt `model_picker()` to include $R^2_{adj}$ in its analysis. Note that you'll have to add certain inputs that you used in `r2_adj()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "\n",
    "def model_picker(y_true, y_preds_1, y_preds2, p_1, n_1, p_2, n_2):\n",
    "    r2_adj_1 = r2_adj(y_true, y_preds_1, p_1, n_1)\n",
    "    r2_adj_2 = r2_adj(y_true, y_preds_2, p_2, n_2)\n",
    "    \n",
    "    r2_1 = metrics.r2_score(y_preds_1,y_true)\n",
    "    r2_2 = metrics.r2_score(y_preds_2,y_true)\n",
    "    \n",
    "    mse_1 = metrics.mean_squared_error(y_preds_1,y_true)\n",
    "    mse_2 = metrics.mean_squared_error(y_preds_2,y_true)\n",
    "    \n",
    "    rmse_1 = mse_1 ** 0.5\n",
    "    rmse_2 = mse_2 ** 0.5\n",
    "    \n",
    "    medae_1 = metrics.median_absolute_error(y_preds_1,y_true)\n",
    "    medae_2 = metrics.median_absolute_error(y_preds_2,y_true)\n",
    "    \n",
    "    msle_1 = metrics.mean_squared_log_error(y_preds_1, y_true)\n",
    "    msle_2 = metrics.mean_squared_log_error(y_preds_2, y_true)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
